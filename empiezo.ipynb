{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - PySpark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El enlace al repositorio es el siguiente: [GitHub](https://github.com/MiguelGG03/Final_Poject_PySpark.git)\n",
    "\n",
    "Importamos la librer√≠a para hacer unas pruebas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from dask import dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/mglez/OneDrive/Escritorio/GitHub/Final_Poject_PySpark/air_trafic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mglez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\backends.py:135\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\mglez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:755\u001b[0m, in \u001b[0;36mmake_reader.<locals>.read\u001b[1;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\n\u001b[0;32m    743\u001b[0m     urlpath,\n\u001b[0;32m    744\u001b[0m     blocksize\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    753\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    754\u001b[0m ):\n\u001b[1;32m--> 755\u001b[0m     \u001b[39mreturn\u001b[39;00m read_pandas(\n\u001b[0;32m    756\u001b[0m         reader,\n\u001b[0;32m    757\u001b[0m         urlpath,\n\u001b[0;32m    758\u001b[0m         blocksize\u001b[39m=\u001b[39mblocksize,\n\u001b[0;32m    759\u001b[0m         lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m    760\u001b[0m         compression\u001b[39m=\u001b[39mcompression,\n\u001b[0;32m    761\u001b[0m         sample\u001b[39m=\u001b[39msample,\n\u001b[0;32m    762\u001b[0m         sample_rows\u001b[39m=\u001b[39msample_rows,\n\u001b[0;32m    763\u001b[0m         enforce\u001b[39m=\u001b[39menforce,\n\u001b[0;32m    764\u001b[0m         assume_missing\u001b[39m=\u001b[39massume_missing,\n\u001b[0;32m    765\u001b[0m         storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m    766\u001b[0m         include_path_column\u001b[39m=\u001b[39minclude_path_column,\n\u001b[0;32m    767\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    768\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mglez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:559\u001b[0m, in \u001b[0;36mread_pandas\u001b[1;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m b_lineterminator \u001b[39m=\u001b[39m lineterminator\u001b[39m.\u001b[39mencode()\n\u001b[1;32m--> 559\u001b[0m b_out \u001b[39m=\u001b[39m read_bytes(\n\u001b[0;32m    560\u001b[0m     urlpath,\n\u001b[0;32m    561\u001b[0m     delimiter\u001b[39m=\u001b[39mb_lineterminator,\n\u001b[0;32m    562\u001b[0m     blocksize\u001b[39m=\u001b[39mblocksize,\n\u001b[0;32m    563\u001b[0m     sample\u001b[39m=\u001b[39msample,\n\u001b[0;32m    564\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[0;32m    565\u001b[0m     include_path\u001b[39m=\u001b[39minclude_path_column,\n\u001b[0;32m    566\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(storage_options \u001b[39mor\u001b[39;00m {}),\n\u001b[0;32m    567\u001b[0m )\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m include_path_column:\n",
      "File \u001b[1;32mc:\\Users\\mglez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\bytes\\core.py:109\u001b[0m, in \u001b[0;36mread_bytes\u001b[1;34m(urlpath, delimiter, not_zero, blocksize, sample, compression, include_path, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot do chunked reads on compressed files. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo read, set blocksize=None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m     )\n\u001b[1;32m--> 109\u001b[0m size \u001b[39m=\u001b[39m fs\u001b[39m.\u001b[39;49minfo(path)[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    110\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mglez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fsspec\\implementations\\local.py:87\u001b[0m, in \u001b[0;36mLocalFileSystem.info\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m---> 87\u001b[0m out \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path, follow_symlinks\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     88\u001b[0m link \u001b[39m=\u001b[39m stat\u001b[39m.\u001b[39mS_ISLNK(out\u001b[39m.\u001b[39mst_mode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/mglez/OneDrive/Escritorio/GitHub/Final_Poject_PySpark/air_trafic.csv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mglez\\OneDrive\\Escritorio\\GitHub\\Final_Poject_PySpark\\empiezo.ipynb Cell 4\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mglez/OneDrive/Escritorio/GitHub/Final_Poject_PySpark/empiezo.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mair_trafic.csv\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mglez/OneDrive/Escritorio/GitHub/Final_Poject_PySpark/empiezo.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\mglez\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dask\\backends.py:137\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(\n\u001b[0;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling the \u001b[39m\u001b[39m{\u001b[39;00mfuncname(func)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmethod registered to the \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackend\u001b[39m}\u001b[39;00m\u001b[39m backend.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOriginal Message: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:/Users/mglez/OneDrive/Escritorio/GitHub/Final_Poject_PySpark/air_trafic.csv'"
     ]
    }
   ],
   "source": [
    "df= dd.read_csv(\"air_trafic.csv\", sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile empiezo.txt\n",
    "Esto es un archivo de texto\n",
    "para probar el uso de Spark\n",
    "en Jupyter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
